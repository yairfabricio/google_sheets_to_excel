---
title: "üß∞ ETL desde Google Sheets ‚Äî Consolidaci√≥n 2023‚Äì2025"
description: >
  Este repositorio contiene un Jupyter Notebook que implementa un flujo de extracci√≥n
  y transformaci√≥n de datos (ET/ETL) desde Google Sheets y consolida informaci√≥n
  de m√∫ltiples hojas/a√±os (2023, 2024, 2025) en un √∫nico DataFrame listo para an√°lisis.

summary: |
  Se autentica con una cuenta de servicio (credenciales.json), lee datos de Google Sheets,
  normaliza columnas y estandariza textos, fechas y pa√≠ses. Produce un dataset consolidado
  y puede incluir una etapa opcional de carga (Load) a CSV, BD o nueva hoja de Google Sheets.

diagram: |
  Google Sheets (m√∫ltiples hojas / a√±os)
            ‚Üì
        Extract (gspread)
            ‚Üì
      Transform (pandas: limpieza de columnas, normalizaci√≥n de texto, parseo de fechas, estandarizaci√≥n de pa√≠ses)
            ‚Üì
     DataFrame consolidado ‚úÖ
            ‚Üì
     (opcional) Load: CSV / BD / otro Sheet

features:
  - "üîê Autenticaci√≥n v√≠a Service Account (credenciales.json)"
  - "üì• Lectura desde Google Sheets usando gspread y gspread_dataframe"
  - "üßπ Normalizaci√≥n de columnas y nombres"
  - "üóìÔ∏è Parseo de fechas heterog√©neas"
  - "üåé Estandarizaci√≥n de pa√≠ses"
  - "üî§ Limpieza de texto (acentos y caracteres no deseados)"
  - "üß± Consolidaci√≥n de informaci√≥n 2023‚Äì2025"
  - "‚è≥ Reintentos simples con time.sleep para evitar l√≠mites de API"

dependencies:
  - pandas
  - numpy
  - gspread
  - oauth2client
  - gspread-dataframe
  - built-in: [time, re, unicodedata, datetime]

credentials: |
  1. Crea una Service Account en Google Cloud Console y descarga el JSON.
  2. Coloca el archivo en el proyecto como credenciales.json.
  3. Comparte tus Google Sheets con el correo de la service account (lector/editor).
  4. Scopes usados:
     - https://www.googleapis.com/auth/spreadsheets
     - https://www.googleapis.com/auth/drive
  ‚ö†Ô∏è Nunca subas credenciales.json a GitHub. A√±√°delo a .gitignore.

usage: |
  1. Abre ETL_google_sheets.ipynb en Jupyter o VS Code.
  2. Aseg√∫rate de tener credenciales.json en el mismo directorio.
  3. Ejecuta todas las celdas.
  4. Obtendr√°s un DataFrame consolidado con los datos 2023‚Äì2025.

functions:
  - name: normalizar_columna
    description: "Homogeniza nombres de columnas (min√∫sculas, sin acentos, sin espacios raros)."
  - name: parse_fecha_mixta_especifica
    description: "Convierte fechas con formatos mixtos a un datetime consistente."
  - name: _norm_txt
    description: "Limpia texto eliminando acentos y normalizando caracteres."
  - name: normalize_country
    description: "Estandariza nombres de pa√≠ses."

process:
  - "Importa librer√≠as: pandas, numpy, gspread, oauth2client.service_account, gspread_dataframe"
  - "Autenticaci√≥n con ServiceAccountCredentials.from_json_keyfile_name('credenciales.json')"
  - "Lee m√∫ltiples hojas de Google Sheets por a√±o (2023, 2024, 2025)"
  - "Normaliza columnas, fechas y pa√≠ses"
  - "Concatena todos los datos en un √∫nico DataFrame"

etl_stage: "Extract + Transform (puede ampliarse a ETL a√±adiendo carga final)"

load_examples:
  - csv: "df_final.to_csv('consolidado_2023_2025.csv', index=False)"
  - google_sheets: |
      from gspread_dataframe import set_with_dataframe
      ws_out = sh.worksheet("consolidado")
      set_with_dataframe(ws_out, df_final)
  - database: |
      from sqlalchemy import create_engine
      engine = create_engine("postgresql+psycopg2://user:pass@host:5432/db")
      df_final.to_sql("consolidado_gsheets", engine, if_exists="replace", index=False)

validations:
  - "Verifica tipos de datos con df.dtypes"
  - "Revisa duplicados y nulos clave"
  - "Controla outliers num√©ricos"
  - "Valida formatos de fecha consistentes"

best_practices:
  - "Usar .gitignore para credenciales y datos sensibles"
  - "Limpiar salidas del notebook antes de hacer commit"
  - "Dividir funciones largas en m√≥dulos (utils.py)"
  - "Agregar pruebas b√°sicas (asserts sobre conteos/fechas)"

repo_structure: |
  .
  ‚îú‚îÄ‚îÄ ETL_google_sheets.ipynb     # Notebook principal
  ‚îú‚îÄ‚îÄ requirements.txt            # Dependencias (opcional)
  ‚îú‚îÄ‚îÄ README.md                   # Este archivo
  ‚îú‚îÄ‚îÄ data/                       # CSVs o salidas locales (opcional)
  ‚îî‚îÄ‚îÄ credenciales.json           # No subir a git

troubleshooting:
  - "AuthError / 403: comparte el Sheet con la Service Account"
  - "Rate limit / timeouts: usa time.sleep o lotes m√°s peque√±os"
  - "Fechas incorrectas: revisa parse_fecha_mixta_especifica"

license: "MIT (o la que prefieras)"
note: >
  Si lo deseas, se puede generar autom√°ticamente un diccionario de datos
  con nombres de columnas, tipos y ejemplos detectados desde el notebook.
---
